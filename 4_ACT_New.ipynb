{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyP+zxJaL/zOrGUPglIBK0Gr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EhsanHonarvar/Practices/blob/main/4_ACT_New.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ACT New**"
      ],
      "metadata": {
        "id": "Z67d4HsSgqmn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout, LayerNormalization, MultiHeadAttention, Add, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re"
      ],
      "metadata": {
        "id": "zAI4cl6UgySU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets\n",
        "!pip install pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiS9YvEnhFpc",
        "outputId": "7a184bb8-ca90-409e-9ec6-b00517bd1721"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.65.0)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.5.13)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2022.12.7)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.27.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.26.15)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.4)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.22.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "import pandas\n",
        "  \n",
        "od.download(\n",
        "    \"https://www.kaggle.com/datasets/gauravduttakiit/bitcoin-tweets-16m-tweets-with-sentiment-tagged\")\n",
        "\n",
        "\n",
        "\n",
        "# # بارگیری دیتاست\n",
        "# data = pd.read_csv('Bitcoin_tweets_sentiment.csv', encoding='latin1')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MstHXIdkhOc2",
        "outputId": "e0303373-fd0e-4e10-d3dc-40b188d9f2a6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: ehsanhonarvar\n",
            "Your Kaggle Key: ··········\n",
            "Downloading bitcoin-tweets-16m-tweets-with-sentiment-tagged.zip to ./bitcoin-tweets-16m-tweets-with-sentiment-tagged\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.10G/1.10G [00:55<00:00, 21.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# reading the XLSX file\n",
        "file =('bitcoin-tweets-16m-tweets-with-sentiment-tagged/mbsa.csv')\n",
        "full_data = pd.read_csv(file)\n",
        "  \n",
        "# displaying the contents of the XLSX file\n",
        "full_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "OTwPVTKohu0y",
        "outputId": "d1b6f9a7-9b5c-4bfa-929e-eab003aae962"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Date                                               text Sentiment\n",
              "0  2019-05-27  È appena uscito un nuovo video! LES CRYPTOMONN...  Positive\n",
              "1  2019-05-27  Cardano: Digitize Currencies; EOS https://t.co...  Positive\n",
              "2  2019-05-27  Another Test tweet that wasn't caught in the s...  Positive\n",
              "3  2019-05-27  Current Crypto Prices! \\n\\nBTC: $8721.99 USD\\n...  Positive\n",
              "4  2019-05-27  Spiv (Nosar Baz): BITCOIN Is An Asset &amp; NO...  Positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ca4dec47-f3c0-4bef-a32e-e3594eabc521\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>text</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-05-27</td>\n",
              "      <td>È appena uscito un nuovo video! LES CRYPTOMONN...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-05-27</td>\n",
              "      <td>Cardano: Digitize Currencies; EOS https://t.co...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-05-27</td>\n",
              "      <td>Another Test tweet that wasn't caught in the s...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-05-27</td>\n",
              "      <td>Current Crypto Prices! \\n\\nBTC: $8721.99 USD\\n...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-05-27</td>\n",
              "      <td>Spiv (Nosar Baz): BITCOIN Is An Asset &amp;amp; NO...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ca4dec47-f3c0-4bef-a32e-e3594eabc521')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ca4dec47-f3c0-4bef-a32e-e3594eabc521 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ca4dec47-f3c0-4bef-a32e-e3594eabc521');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = full_data.sample(1000000)\n",
        "\n",
        "data.head()\n",
        "print('Total Sample: ',len(data))\n",
        "print(data.groupby(data.Sentiment).count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLACpHhFVmZx",
        "outputId": "4122217b-470d-4808-bc97-84cc8a54d82a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Sample:  1000000\n",
            "             Date    text\n",
            "Sentiment                \n",
            "Negative   503153  503153\n",
            "Neutral        24      24\n",
            "Positive   450632  450632\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# تعریف تابع پیش‌پردازش متن\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'http\\S+', '', str(text)) # حذف لینک‌ها\n",
        "    text = re.sub(r'[^\\w\\s]','',text) # حذف نقطه، ویرگول و سایر نویسه‌های غیر حروف و اعداد\n",
        "    text = re.sub(r'\\d+', '', text) # حذف اعداد\n",
        "    text = text.lower() # تبدیل به حروف کوچک\n",
        "    return text"
      ],
      "metadata": {
        "id": "h9VrpLQ1hZNq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# پیش‌پردازش داده‌ها\n",
        "data['text'] = data['text'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "dPr0wSslnYGu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# تبدیل برچسب‌ها به باینری (مثبت یا منفی) از نوع int\n",
        "data['Sentiment'] = data['Sentiment'].apply(lambda x: 1 if (x =='positive' or x =='Positive') else 0)\n",
        "\n",
        "# تقسیم داده‌ها به دو مجموعه آموزش و آزمون\n",
        "train_size = int(len(data) * 0.8)\n",
        "train_data = data[:train_size]\n",
        "test_data = data[train_size:]"
      ],
      "metadata": {
        "id": "NxQ33R9thqcZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# تبدیل متن به توکن‌ها\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(train_data['text'])\n",
        "train_sequences = tokenizer.texts_to_sequences(train_data['text'])\n",
        "test_sequences = tokenizer.texts_to_sequences(test_data['text'])\n",
        "\n",
        "# پر کردن صفر در صورت نیاز\n",
        "train_sequences = pad_sequences(train_sequences, padding='post')\n",
        "test_sequences = pad_sequences(test_sequences, padding='post')"
      ],
      "metadata": {
        "id": "LXd0Ob9Eh9s8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# تعریف پارامترهای شبکه\n",
        "# MAX_SEQUENCE_LENGTH = len(max(train_sequences, key=len))\n",
        "MAX_SEQUENCE_LENGTH = 20\n",
        "VOCAB_SIZE = len(tokenizer.word_index) + 1\n",
        "FILTERS = 64\n",
        "KERNEL_SIZE = 3\n",
        "DROPOUT_RATE = 0.5\n",
        "NUM_HEADS = 8\n",
        "D_MODEL = 64\n",
        "NUM_LAYERS = 4\n",
        "FFN_UNITS = 256\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 64\n",
        "LEARNING_RATE = 0.001"
      ],
      "metadata": {
        "id": "4kIA1o3Th9wE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# تعریف مدل\n",
        "input_layer = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
        "embedding_layer = tf.keras.layers.Embedding(input_dim=VOCAB_SIZE, output_dim=D_MODEL, input_length=MAX_SEQUENCE_LENGTH)(input_layer)\n",
        "conv_layer = Conv1D(filters=FILTERS, kernel_size=KERNEL_SIZE, activation='gelu')(embedding_layer)\n",
        "max_pooling_layer = MaxPooling1D(pool_size=2)(conv_layer)\n",
        "flatten_layer = Flatten()(max_pooling_layer)\n",
        "dropout_layer = Dropout(rate=DROPOUT_RATE)(flatten_layer)"
      ],
      "metadata": {
        "id": "NMCEMPHBh9zn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CW2N1pXruyfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######## اضافه شده 3\n",
        "\n",
        "\n",
        "# تعریف لایه‌های ترانسفورمر\n",
        "encoder_layers = []\n",
        "for i in range(NUM_LAYERS):\n",
        "  multi_head_attention_layer = MultiHeadAttention(num_heads=NUM_HEADS, key_dim=D_MODEL)(dropout_layer, dropout_layer, dropout_layer)\n",
        "  add_attention_layer = Add()([multi_head_attention_layer, dropout_layer])\n",
        "  layer_norm1 = LayerNormalization()(add_attention_layer)\n",
        "  feed_forward_layer = Dense(units=FFN_UNITS, activation='gelu')(layer_norm1)\n",
        "  add_feed_forward_layer = Add()([feed_forward_layer, layer_norm1])\n",
        "  layer_norm2 = LayerNormalization()(add_feed_forward_layer)\n",
        "  encoder_layers.append(layer_norm2)\n",
        "  dropout_layer = Dropout(rate=DROPOUT_RATE)(layer_norm2)\n",
        "\n",
        "# ترکیب لایه کانولوشنال با لایه‌های ترانسفورمر\n",
        "concat_layer = tf.keras.layers.concatenate([flatten_layer]+encoder_layers)\n",
        "dense_layer = Dense(units=64, activation='gelu', kernel_regularizer=l2(0.01))(concat_layer)\n",
        "batch_norm_layer = BatchNormalization()(dense_layer)\n",
        "output_layer = Dense(units=1, activation='linear')(batch_norm_layer)\n",
        "output_layer = tf.keras.layers.Activation('softmax')(output_layer)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n"
      ],
      "metadata": {
        "id": "pzJaF34RuclM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "outputId": "be049ef2-3cb2-40f8-f47d-47b4f3a68f9a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-25a045bcf296>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mencoder_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_LAYERS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mmulti_head_attention_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiHeadAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_HEADS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mD_MODEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropout_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0madd_attention_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmulti_head_attention_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_layer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mlayer_norm1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLayerNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd_attention_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/layers/activation/softmax.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m    101\u001b[0m                 )\n\u001b[1;32m    102\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Exception encountered when calling layer 'softmax' (type Softmax).\n\ntuple index out of range\n\nCall arguments received by layer 'softmax' (type Softmax):\n  • inputs=tf.Tensor(shape=(None, 8), dtype=float32)\n  • mask=None"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###### اضافه شده 2\n",
        "\n",
        "\n",
        "# تعریف لایه‌های ترانسفورمر\n",
        "encoder_layers = []\n",
        "for i in range(NUM_LAYERS):\n",
        "  multi_head_attention_layer = MultiHeadAttention(num_heads=NUM_HEADS, key_dim=D_MODEL)(dropout_layer, dropout_layer, dropout_layer)\n",
        "  add_attention_layer = Add()([multi_head_attention_layer, dropout_layer])\n",
        "  layer_norm1 = LayerNormalization()(add_attention_layer)\n",
        "  feed_forward_layer = Dense(units=FFN_UNITS, activation='gelu')(layer_norm1)\n",
        "  add_feed_forward_layer = Add()([feed_forward_layer, layer_norm1])\n",
        "  layer_norm2 = LayerNormalization()(add_feed_forward_layer)\n",
        "  encoder_layers.append(layer_norm2)\n",
        "  dropout_layer = Dropout(rate=DROPOUT_RATE)(layer_norm2)\n",
        "\n",
        "\n",
        "\n",
        "# # تعریف لایه‌های ترانسفورمر\n",
        "# encoder_layers = []\n",
        "# for i in range(NUM_LAYERS):\n",
        "#   multi_head_attention_layer = MultiHeadAttention(num_heads=NUM_HEADS, key_dim=D_MODEL)(dropout_layer)\n",
        "#   add_attention_layer = Add()([multi_head_attention_layer, dropout_layer])\n",
        "#   layer_norm1 = LayerNormalization()(add_attention_layer)\n",
        "#   feed_forward_layer = Dense(units=FFN_UNITS, activation='gelu')(layer_norm1)\n",
        "#   add_feed_forward_layer = Add()([feed_forward_layer, layer_norm1])\n",
        "#   layer_norm2 = LayerNormalization()(add_feed_forward_layer)\n",
        "#   encoder_layers.append(layer_norm2)\n",
        "#   dropout_layer = Dropout(rate=DROPOUT_RATE)(layer_norm2)\n",
        "\n",
        "# ترکیب لایه کانولوشنال با لایه‌های ترانسفورمر\n",
        "concat_layer = tf.keras.layers.concatenate([flatten_layer]+encoder_layers)\n",
        "dense_layer = Dense(units=64, activation='gelu', kernel_regularizer=l2(0.01))(concat_layer)\n",
        "batch_norm_layer = BatchNormalization()(dense_layer)\n",
        "output_layer = Dense(units=1, activation='sigmoid')(batch_norm_layer)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=output_layer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "hU7C9roYh-Ck",
        "outputId": "7b3c3226-6131-4325-cec8-c5b6f6c187d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-8a5ba8bfc713>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mencoder_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_LAYERS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mmulti_head_attention_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiHeadAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_HEADS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mD_MODEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropout_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0madd_attention_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmulti_head_attention_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_layer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mlayer_norm1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLayerNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd_attention_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/layers/activation/softmax.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m    101\u001b[0m                 )\n\u001b[1;32m    102\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Exception encountered when calling layer 'softmax' (type Softmax).\n\ntuple index out of range\n\nCall arguments received by layer 'softmax' (type Softmax):\n  • inputs=tf.Tensor(shape=(None, 8), dtype=float32)\n  • mask=None"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# کامپایل مدل\n",
        "optimizer = Adam(learning_rate=LEARNING_RATE)\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# آموزش مدل\n",
        "history = model.fit(train_sequences, train_data['Sentiment'], epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(test_sequences, test_data['Sentiment']))"
      ],
      "metadata": {
        "id": "biZxd1cbjUZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ارزیابی مدل\n",
        "test_loss, test_acc = model.evaluate(test_sequences, test_data['Sentiment'])\n",
        "print('Test Loss:', test_loss)\n",
        "print('Test Accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "vbimTy-1jUcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UIROZWRnjUgk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}