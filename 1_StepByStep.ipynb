{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EhsanHonarvar/Practices/blob/main/1_StepByStep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwrVRMdAY2bD"
      },
      "source": [
        "# **from:**\n",
        "https://github.com/theCaiGuy/Twitter-Sentiment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60Px7ONTiusm",
        "outputId": "78da978d-c454-49dd-8bac-25333e3bc99c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZVhvAc4huG3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvTYQ1HmiGao"
      },
      "outputs": [],
      "source": [
        "# ########## With Bitcoin Tweets Data ################ Start\n",
        "# tweets = pd.read_csv('/kaggle/input/bitcoin-tweets-16m-tweets-with-sentiment-tagged/mbsa.csv')\n",
        "# tweets.head()\n",
        "# ########## With Bitcoin Tweets Data ################ End\n",
        "\n",
        "\n",
        "full_data = pd.read_csv(\"/content/drive/MyDrive/Thesis/training.1600000.processed.noemoticon.csv\", names= ['Pos_Neg','id','date','query_string','user','Content'] , encoding = 'latin-1')\n",
        "full_n = full_data.shape[0]\n",
        "full_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "g4-5MC2Jlie2",
        "outputId": "ec6dbb36-6343-48d5-81d8-3fb440789f3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Pos_Neg          id                          date query_string  \\\n",
              "0        0  1467810369  Mon Apr 06 22:19:45 PDT 2009     NO_QUERY   \n",
              "1        0  1467810672  Mon Apr 06 22:19:49 PDT 2009     NO_QUERY   \n",
              "2        0  1467810917  Mon Apr 06 22:19:53 PDT 2009     NO_QUERY   \n",
              "3        0  1467811184  Mon Apr 06 22:19:57 PDT 2009     NO_QUERY   \n",
              "4        0  1467811193  Mon Apr 06 22:19:57 PDT 2009     NO_QUERY   \n",
              "\n",
              "              user                                            Content  \n",
              "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
              "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
              "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
              "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
              "4           Karoli  @nationwideclass no, it's not behaving at all....  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b06018bf-9e97-4759-9021-98b320151a43\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pos_Neg</th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>query_string</th>\n",
              "      <th>user</th>\n",
              "      <th>Content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b06018bf-9e97-4759-9021-98b320151a43')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b06018bf-9e97-4759-9021-98b320151a43 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b06018bf-9e97-4759-9021-98b320151a43');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "print(type(full_data))\n",
        "full_data.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6pOYVMPDB72",
        "outputId": "138aaf5d-ae29-4c7d-da0a-61885e74c9ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1600000 entries, 0 to 1599999\n",
            "Data columns (total 6 columns):\n",
            " #   Column        Non-Null Count    Dtype \n",
            "---  ------        --------------    ----- \n",
            " 0   Pos_Neg       1600000 non-null  int64 \n",
            " 1   id            1600000 non-null  int64 \n",
            " 2   date          1600000 non-null  object\n",
            " 3   query_string  1600000 non-null  object\n",
            " 4   user          1600000 non-null  object\n",
            " 5   Content       1600000 non-null  object\n",
            "dtypes: int64(2), object(4)\n",
            "memory usage: 73.2+ MB\n"
          ]
        }
      ],
      "source": [
        "full_data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4eLxkaBdnupU"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiVPaHajjS7L"
      },
      "outputs": [],
      "source": [
        "train_data, dev_data = sklearn.model_selection.train_test_split(full_data, test_size = 0.05)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0amD8yamRbA",
        "outputId": "e70d6935-9400-4705-f18f-909462578f79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n"
          ]
        }
      ],
      "source": [
        "print(type(train_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grNCayIMjS_G",
        "outputId": "ea4e3b17-fb6e-4d29-9515-69f15fbae978"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1600000\n"
          ]
        }
      ],
      "source": [
        "print(full_n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjkDSIJmmtzF"
      },
      "outputs": [],
      "source": [
        "# full_data = full_data [:320000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FppqjZDVnGGU",
        "outputId": "ee21fb92-1e5b-4afb-bff4-f80e0daa04a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "320000\n"
          ]
        }
      ],
      "source": [
        "# full_n = full_data.shape[0]\n",
        "# print(full_n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZjPy7-VndkC"
      },
      "outputs": [],
      "source": [
        "# train_data, dev_data = sklearn.model_selection.train_test_split(full_data, test_size = 0.40) #It was 0.04"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-zdaSkgjnjF"
      },
      "outputs": [],
      "source": [
        "# train_data = train_data[:96000]\n",
        "# dev_data = dev_data[:64000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pr1wVx1FnjiP",
        "outputId": "ef2f49c0-ae5f-4ad5-e30a-d24cc794e88f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1600000 \n",
            " 1520000 \n",
            " 80000\n"
          ]
        }
      ],
      "source": [
        "print(full_data.shape[0],'\\n',train_data.shape[0],'\\n',dev_data.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPaBcm-n0VXn",
        "outputId": "ebc6f552-1e77-48e3-9695-4a3caa1cfd5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.series.Series'>\n",
            "<class 'list'>\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Get ground truth x and y values\n",
        "train_x_raw = train_data.loc[:][\"Content\"]\n",
        "train_y = [0.0 if y == 0 else 1.0 for y in train_data.loc[:][\"Pos_Neg\"]]\n",
        "\n",
        "dev_x_raw = dev_data.loc[:][\"Content\"]\n",
        "dev_y = [0.0 if y == 0 else 1.0 for y in dev_data.loc[:][\"Pos_Neg\"]]\n",
        "#print (dev_y)\n",
        "\n",
        "print(type(train_x_raw))\n",
        "print(type(dev_y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXXgPr5d8XPO"
      },
      "outputs": [],
      "source": [
        "# import gensim.downloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Jdad9Xh8ZEi",
        "outputId": "bfde9e44-1184-4294-b1ff-44e2bc1d557e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 387.1/387.1MB downloaded\n"
          ]
        }
      ],
      "source": [
        "# glove_vectors = gensim.downloader.load('glove-twitter-100')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qSsv2dM-HTz",
        "outputId": "776950d4-0e6e-4033-9bc9-e13088ac81cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<gensim.models.keyedvectors.Word2VecKeyedVectors object at 0x7f6276b31050>\n"
          ]
        }
      ],
      "source": [
        "# print(glove_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IXE1mfc0Vkn",
        "outputId": "d938a4ea-7475-44c0-c7b3-466fc86921ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'dict'>\n",
            "<class 'list'>\n"
          ]
        }
      ],
      "source": [
        "char_vectors = {}\n",
        "for line in open('/content/drive/MyDrive/Datasets/glove.6B.100d.txt').readlines():\n",
        "    sp = line.strip().split()\n",
        "    if len(sp) == 0: continue\n",
        "    char_vectors[sp[0]] = [float(x) for x in sp[1:]]\n",
        "\n",
        "print(type(char_vectors))\n",
        "print(type(char_vectors[sp[0]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIwF9nc71ipN",
        "outputId": "1cf36cd8-f061-411a-b577-b01412bae846"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400000\n",
            "100\n"
          ]
        }
      ],
      "source": [
        "print(len(char_vectors))\n",
        "print(len(char_vectors[sp[0]]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiERQ3mLzh3G",
        "outputId": "ae6270a5-6a7f-4af5-c63a-bbd29b01aad9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.28365, -0.6263, -0.44351, 0.2177, -0.087421, -0.17062, 0.29266, -0.024899, 0.26414, -0.17023, 0.25817, 0.097484, -0.33103, -0.43859, 0.0095799, 0.095624, -0.17777, 0.38886, 0.27151, 0.14742, -0.43973, -0.26588, -0.024271, 0.27186, -0.36761, -0.24827, -0.20815, 0.22128, -0.044409, 0.021373, 0.24594, 0.26143, 0.29303, 0.13281, 0.082232, -0.12869, 0.1622, -0.22567, -0.060348, 0.28703, 0.11381, 0.34839, 0.3419, 0.36996, -0.13592, 0.0062694, 0.080317, 0.0036251, 0.43093, 0.01882, 0.31008, 0.16722, 0.074112, -0.37745, 0.47363, 0.41284, 0.24471, 0.075965, -0.51725, -0.49481, 0.526, -0.074645, 0.41434, -0.1956, -0.16544, -0.045649, -0.40153, -0.13136, -0.4672, 0.18825, 0.2612, 0.16854, 0.22615, 0.62992, -0.1288, 0.055841, 0.01928, 0.024572, 0.46875, 0.2582, -0.31672, 0.048591, 0.3277, -0.50141, 0.30855, 0.11997, -0.25768, -0.039867, -0.059672, 0.5525, 0.13885, -0.22862, 0.071792, -0.43208, 0.5398, -0.085806, 0.032651, 0.43678, -0.82607, -0.15701]\n",
            "[-0.046539, 0.61966, 0.56647, -0.46584, -1.189, 0.44599, 0.066035, 0.3191, 0.14679, -0.22119, 0.79239, 0.29905, 0.16073, 0.025324, 0.18678, -0.31001, -0.28108, 0.60515, -1.0654, 0.52476, 0.064152, 1.0358, -0.40779, -0.38011, 0.30801, 0.59964, -0.26991, -0.76035, 0.94222, -0.46919, -0.18278, 0.90652, 0.79671, 0.24825, 0.25713, 0.6232, -0.44768, 0.65357, 0.76902, -0.51229, -0.44333, -0.21867, 0.3837, -1.1483, -0.94398, -0.15062, 0.30012, -0.57806, 0.20175, -1.6591, -0.079195, 0.026423, 0.22051, 0.99714, -0.57539, -2.7266, 0.31448, 0.70522, 1.4381, 0.99126, 0.13976, 1.3474, -1.1753, 0.0039503, 1.0298, 0.064637, 0.90887, 0.82872, -0.47003, -0.10575, 0.5916, -0.4221, 0.57331, -0.54114, 0.10768, 0.39784, -0.048744, 0.064596, -0.61437, -0.286, 0.5067, -0.49758, -0.8157, 0.16408, -1.963, -0.26693, -0.37593, -0.95847, -0.8584, -0.71577, -0.32343, -0.43121, 0.41392, 0.28374, -0.70931, 0.15003, -0.2154, -0.37616, -0.032502, 0.8062]\n",
            "[-0.038194, -0.24487, 0.72812, -0.39961, 0.083172, 0.043953, -0.39141, 0.3344, -0.57545, 0.087459, 0.28787, -0.06731, 0.30906, -0.26384, -0.13231, -0.20757, 0.33395, -0.33848, -0.31743, -0.48336, 0.1464, -0.37304, 0.34577, 0.052041, 0.44946, -0.46971, 0.02628, -0.54155, -0.15518, -0.14107, -0.039722, 0.28277, 0.14393, 0.23464, -0.31021, 0.086173, 0.20397, 0.52624, 0.17164, -0.082378, -0.71787, -0.41531, 0.20335, -0.12763, 0.41367, 0.55187, 0.57908, -0.33477, -0.36559, -0.54857, -0.062892, 0.26584, 0.30205, 0.99775, -0.80481, -3.0243, 0.01254, -0.36942, 2.2167, 0.72201, -0.24978, 0.92136, 0.034514, 0.46745, 1.1079, -0.19358, -0.074575, 0.23353, -0.052062, -0.22044, 0.057162, -0.15806, -0.30798, -0.41625, 0.37972, 0.15006, -0.53212, -0.2055, -1.2526, 0.071624, 0.70565, 0.49744, -0.42063, 0.26148, -1.538, -0.30223, -0.073438, -0.28312, 0.37104, -0.25217, 0.016215, -0.017099, -0.38984, 0.87424, -0.72569, -0.51058, -0.52028, -0.1459, 0.8278, 0.27062]\n"
          ]
        }
      ],
      "source": [
        "# print(char_vectors)\n",
        "\n",
        "print(char_vectors[sp[0]])\n",
        "print(char_vectors['i'])\n",
        "print(char_vectors['the'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8nXGF4pB5j2",
        "outputId": "27a7371a-26f5-4122-d0b4-be93b08f1b57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.73704, 0.66283, 1.0574, 0.010218, 0.39815, -1.312, -0.82644, 0.52181, 0.71802, 1.4257, 0.32899, -0.70814, 1.0913, 0.39288, -0.539, 0.34568, -0.44541, -0.68467, -1.0251, -0.28259, 0.24643, -0.12216, 0.6778, 0.037953, -0.49667, 0.22861, -0.42924, 0.82565, 0.92749, 0.82861, -0.29846, 0.078323, -0.6415, -0.049715, 0.097872, 0.11647, 0.50231, -0.66332, -0.8046, -0.13047, -1.3995, 0.16397, 0.51603, -0.53419, 0.20498, -1.3766, 0.94354, 0.061697, -0.050002, -0.48968, 0.7309, 0.99181, 0.44085, 1.4769, -0.9737, -1.8742, 0.13894, -0.84341, 0.75602, -0.35825, -0.079888, -0.50491, 0.083148, -0.71243, 0.65236, 0.6766, 0.28151, 0.75826, -0.65151, 0.55292, 0.84885, -0.081808, 0.030953, -0.18909, 0.50983, 0.19043, 0.25679, -0.16961, -0.8492, 0.30048, 1.5914, 0.16726, -0.28329, -0.49085, -0.93667, 0.33378, 0.0065908, 0.76209, 0.44116, -0.77764, -0.44926, 0.57403, -0.44588, -0.31071, -0.91459, 0.31412, -0.343, -0.27904, 0.68867, -0.17311]\n"
          ]
        }
      ],
      "source": [
        "print(char_vectors['iran'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFg3qYTmI3Yd",
        "outputId": "cf9168de-dbeb-45a0-d2d2-54df562fce76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "import string\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qI7sJYfdLROw"
      },
      "outputs": [],
      "source": [
        "\n",
        "SEED = 1234\n",
        "UNK = '<unk>'\n",
        "PAD = '<pad>'\n",
        "\n",
        "TWEET_LEN = 20\n",
        "EMBED_LEN = 100\n",
        "N_EPOCHS = 70 #4000\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69RPOZWw0Vod"
      },
      "outputs": [],
      "source": [
        "#>Creation of tok2id dictionary base on Contents\n",
        "tok2id = {}\n",
        "for ex in full_data['Content']:\n",
        "    for w in word_tokenize(ex):\n",
        "        if w in string.punctuation:\n",
        "            continue\n",
        "        if not w in tok2id:\n",
        "            tok2id[w] = len(tok2id)\n",
        "\n",
        "tok2id[UNK] = len(tok2id)\n",
        "tok2id[PAD] = len(tok2id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NARI3QixZK0A",
        "outputId": "b118f310-b086-40d7-e331-63103f319c20"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "875221"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "len(tok2id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ok3p7VhPtxG"
      },
      "outputs": [],
      "source": [
        "#>Function for Tokenization of Sentences as Vector of tokens\n",
        "def vectorize(examples, tok2id):\n",
        "    vec_examples = []\n",
        "    for ex in examples:\n",
        "        #print (ex)\n",
        "        sentence = []\n",
        "        for w in word_tokenize(ex):\n",
        "            if w in string.punctuation:\n",
        "                continue\n",
        "            if w in tok2id:\n",
        "                sentence.append(tok2id[w])\n",
        "        if len(sentence) < TWEET_LEN:\n",
        "            sentence += [tok2id[PAD] for i in range(TWEET_LEN - len(sentence))]\n",
        "        else:\n",
        "            sentence = sentence[:TWEET_LEN]\n",
        "        vec_examples.append(sentence)\n",
        "    return vec_examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7sA8qQ_EZ7T"
      },
      "outputs": [],
      "source": [
        "train_x = vectorize(train_x_raw, tok2id)\n",
        "\n",
        "dev_x = vectorize(dev_x_raw, tok2id)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhw7jr_DWFMf"
      },
      "outputs": [],
      "source": [
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "rMuVcAbRU7FW",
        "outputId": "55c3dda1-86b4-4f86-d171-48ac2d925dd1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-55cde9f4-ce07-4478-b550-5c0a26edd797\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-55cde9f4-ce07-4478-b550-5c0a26edd797\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving TweetDataset.py to TweetDataset.py\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'TweetDataset.py': b'from torch.utils.data import Dataset\\n\\nclass TweetDataset(Dataset):\\n    \"\"\"Face Landmarks dataset.\"\"\"\\n\\n    def __init__(self, X, Y):\\n        self.x = X\\n        self.y = Y\\n\\n    def __len__(self):\\n        return len(self.x)\\n\\n    def __getitem__(self, idx):\\n        content = self.x[idx]\\n        label = self.y[idx]\\n        sample = {\\'content\\': content, \\'label\\': label}\\n\\n        return sample\\n\\ndataset = TweetDataset(None, None)\\n'}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWjX90tWU0M7"
      },
      "outputs": [],
      "source": [
        "# import TweetDataset\n",
        "# import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxQClHg6f6uX"
      },
      "outputs": [],
      "source": [
        "###Instead Above##\n",
        "# from torch.utils.data import Dataset\n",
        "\n",
        "# class TweetDataset(Dataset):\n",
        "#     \"\"\"Face Landmarks dataset.\"\"\"\n",
        "\n",
        "#     def __init__(self, X, Y):\n",
        "#         self.x = X\n",
        "#         self.y = Y\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.x)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         content = self.x[idx]\n",
        "#         label = self.y[idx]\n",
        "#         sample = {'content': content, 'label': label}\n",
        "\n",
        "#         return sample\n",
        "\n",
        "# dataset = TweetDataset(None, None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIwKyTSZxVMI"
      },
      "source": [
        "# **#?#**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9yggROuZTBx"
      },
      "outputs": [],
      "source": [
        "\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class TweetDataset(Dataset):\n",
        "    \"\"\"Face Landmarks dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, X, Y):\n",
        "        self.x = X\n",
        "        self.y = Y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        content = self.x[idx]\n",
        "        label = self.y[idx]\n",
        "        sample = {'content': content, 'label': label}\n",
        "\n",
        "        return sample\n",
        "\n",
        "dataset = TweetDataset(None, None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-XOSBYmU1fG"
      },
      "outputs": [],
      "source": [
        "#>Definition of Function to Creat embedding_matrix based on tokens and GLOVE embedding vectors\n",
        "import numpy as np\n",
        "def build_embeddings(tok2id, char_vectors):\n",
        "    embeddings_matrix = np.asarray(np.random.normal(0, 0.9, (len(tok2id), EMBED_LEN)), dtype='float32')\n",
        "\n",
        "    for token in tok2id:\n",
        "        i = tok2id[token]\n",
        "        if token in char_vectors:\n",
        "            embeddings_matrix[i] = char_vectors[token]\n",
        "        elif token.lower() in char_vectors:\n",
        "            embeddings_matrix[i] = char_vectors[token.lower()]\n",
        "\n",
        "    return embeddings_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3jAUfZ0EZ-i"
      },
      "outputs": [],
      "source": [
        "train_dataset = TweetDataset(train_x, train_y)\n",
        "dev_dataset = TweetDataset(dev_x, dev_y)\n",
        "\n",
        "embeddings = build_embeddings(tok2id, char_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1ikvz8afYNo",
        "outputId": "505862c4-6036-4ff4-b958-f35d4bfcd33a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "875221\n",
            "100\n"
          ]
        }
      ],
      "source": [
        "print(len(embeddings))\n",
        "print(len(embeddings[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETR4gayIaREu"
      },
      "outputs": [],
      "source": [
        "# files.upload() # convblock, convblockdeeper, DeepCNN, DeeperCnn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wf7QB3aeeQFU"
      },
      "source": [
        "# **Building Conv Blocks**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqazTsWhf__t"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "from typing import List, Tuple, Dict, Set, Union\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.utils\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n88pTfzBgI1-"
      },
      "outputs": [],
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, num_filters, k = 5, stride = 1):\n",
        "        \"\"\" Initialize a CNN network with a kernel of size k,  \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.num_filters = num_filters\n",
        "        self.k = k\n",
        "        self.stride = stride\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channels = in_channels, out_channels = num_filters, kernel_size = k, bias = True, padding = 2)\n",
        "        self.batch_norm1 = nn.BatchNorm1d(num_filters)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        #torch.nn.init.xavier_uniform_(self.conv1.weight)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(in_channels = num_filters, out_channels = num_filters, kernel_size = k, bias = True, padding = 2)\n",
        "        self.batch_norm2 = nn.BatchNorm1d(num_filters)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        #torch.nn.init.xavier_uniform_(self.conv2.weight)\n",
        "\n",
        "        self.pool = nn.MaxPool1d(kernel_size = 2)\n",
        "\n",
        "    def forward(self, x, print_sizes = False) -> torch.Tensor:\n",
        "        \"\"\" Input x of size (batch size, embed_size, sent_len) and output of size [batchsize, embed_size] \"\"\"\n",
        "\n",
        "        x_conv1 = self.conv1(x)\n",
        "        x_relu1 = self.relu1(x_conv1)\n",
        "        x_bn = self.batch_norm1(x_relu1)\n",
        "        if print_sizes: print (x_bn.shape)\n",
        "\n",
        "        x_conv2 = self.batch_norm2(self.relu2(self.conv2(x_bn)))\n",
        "        if print_sizes: print (x_conv2.shape)\n",
        "\n",
        "        x_pool = self.pool(x_conv2)\n",
        "        # print (x_pool)\n",
        "        if print_sizes: print(x_pool.shape)\n",
        "\n",
        "        return x_pool\n",
        "\n",
        "# def test_all():\n",
        "#     batch_size = 3\n",
        "#     embed_size = 5\n",
        "#     sent_len = 6\n",
        "#     num_filters = 6\n",
        "#\n",
        "#     fake_input = torch.tensor(np.zeros((batch_size, embed_size, sent_len)), dtype = torch.float32)\n",
        "#     block = ConvBlock(embed_size, num_filters)\n",
        "#     print (block.forward(fake_input, True))\n",
        "#\n",
        "#\n",
        "# if __name__ == '__main__':\n",
        "#     #test_intermediate_sizes()\n",
        "#     #test_output()\n",
        "#     test_all()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rk0nBQF7f2pf"
      },
      "outputs": [],
      "source": [
        "class DeepCNN(nn.Module):\n",
        "    def __init__(self, embeddings, dropout=0.5):\n",
        "        super().__init__()\n",
        "\n",
        "        self.batch_size = embeddings.shape[1]\n",
        "\n",
        "        # Freeze pretrained GloVe embeddings\n",
        "        self.embedding = nn.Embedding(embeddings.shape[0], embeddings.shape[1])\n",
        "        self.embedding.weight = nn.Parameter(torch.tensor(embeddings))\n",
        "        self.embedding.weight.requires_grad = False\n",
        "\n",
        "        self.conv = nn.Conv1d(in_channels=embeddings.shape[1], out_channels=128, kernel_size=5, padding = 2)\n",
        "        #torch.nn.init.xavier_uniform_(self.conv.weight)\n",
        "        self.block = ConvBlock(128, 256)\n",
        "        self.block2 = ConvBlock(256, 256)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc = nn.Linear(5 * 256, 256)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.fc2 = nn.Linear(256, 1)\n",
        "        #torch.nn.init.xavier_uniform_(self.fc.weight)\n",
        "\n",
        "    def forward(self, x, print_sizes = False):\n",
        "        # x.shape = (sent_len, batch_size)\n",
        "        x = x.permute(1, 0)\n",
        "        if print_sizes: print (\"x.shape: \" + str(x.shape))\n",
        "        # x.shape = (batch_size, sent_len)\n",
        "\n",
        "        x_emb = self.embedding(x).permute(0, 2, 1)\n",
        "        if print_sizes: print (\"x_emb.shape: \" + str(x_emb.shape))\n",
        "        # x_emb.shape = (batch_size, emb_size, sent_len)\n",
        "\n",
        "        x_conv = self.conv(x_emb)\n",
        "        # x_conv.shape = (batch_size, 128, sent_len)\n",
        "        if print_sizes: print (\"x_conv.shape: \" + str(x_conv.shape))\n",
        "\n",
        "        x_block = self.block.forward(x_conv)\n",
        "        # x_block.shape = (batch_size, 128, sent_len / 2)\n",
        "        if print_sizes: print (\"x_block.shape: \" + str(x_block.shape))\n",
        "\n",
        "        x_block_2 = self.block2.forward(x_block)\n",
        "        # x_block.shape = (batch_size, 256, sent_len / 4)\n",
        "        if print_sizes: print (\"x_block_2.shape: \" + str(x_block_2.shape))\n",
        "\n",
        "        x_cat = x_block_2.view(-1, x_block_2.shape[1] * x_block_2.shape[2])\n",
        "        # x_cat.shape = (batch_size, 128 * sent_len / 2)\n",
        "        if print_sizes: print (\"x_cat.shape: \" + str(x_cat.shape))\n",
        "\n",
        "        x_fc = self.fc(self.dropout(x_cat))\n",
        "        # x_fc.shape = (batch_size, 1)\n",
        "        if print_sizes: print (\"x_fc.shape: \" + str(x_fc.shape))\n",
        "\n",
        "        x_fc2 = self.fc2(self.dropout2(x_fc))\n",
        "\n",
        "        return x_fc2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_q-K1o20gouW",
        "outputId": "f9b6afca-2563-4afa-dbc4-3d8dd31af4f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 6, 6])\n",
            "torch.Size([3, 6, 6])\n",
            "torch.Size([3, 6, 6])\n",
            "torch.Size([3, 6, 6])\n",
            "torch.Size([3, 6, 3])\n",
            "tensor([[[-0.2099,  0.5904,  0.4115],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [-0.5126,  0.4798,  0.4700],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [-0.4663,  0.8142,  0.3347]],\n",
            "\n",
            "        [[-0.2099,  0.5904,  0.4115],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [-0.5126,  0.4798,  0.4700],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [-0.4663,  0.8142,  0.3347]],\n",
            "\n",
            "        [[-0.2099,  0.5904,  0.4115],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [-0.5126,  0.4798,  0.4700],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [ 0.0000,  0.0000,  0.0000],\n",
            "         [-0.4663,  0.8142,  0.3347]]], grad_fn=<SqueezeBackward1>)\n"
          ]
        }
      ],
      "source": [
        "### convblockdeeper ###\n",
        "# class ConvBlock(nn.Module):\n",
        "#     def __init__(self, in_channels, num_filters, k = 5, stride = 1):\n",
        "#         \"\"\" Initialize a CNN network with a kernel of size k,  \"\"\"\n",
        "#         super().__init__()\n",
        "\n",
        "#         self.in_channels = in_channels\n",
        "#         self.num_filters = num_filters\n",
        "#         self.k = k\n",
        "#         self.stride = stride\n",
        "\n",
        "#         self.conv1 = nn.Conv1d(in_channels = in_channels, out_channels = num_filters, kernel_size = k, bias = True, padding = 2)\n",
        "#         self.batch_norm1 = nn.BatchNorm1d(num_filters)\n",
        "#         self.relu1 = nn.ReLU()\n",
        "\n",
        "#         self.conv2 = nn.Conv1d(in_channels = num_filters, out_channels = num_filters, kernel_size = k, bias = True, padding = 2)\n",
        "#         self.batch_norm2 = nn.BatchNorm1d(num_filters)\n",
        "#         self.relu2 = nn.ReLU()\n",
        "\n",
        "#         self.conv3 = nn.Conv1d(in_channels = num_filters, out_channels = num_filters, kernel_size = k, bias = True, padding = 2)\n",
        "#         self.batch_norm3 = nn.BatchNorm1d(num_filters)\n",
        "#         self.relu3 = nn.ReLU()\n",
        "\n",
        "#         self.conv4 = nn.Conv1d(in_channels = num_filters, out_channels = num_filters, kernel_size = k, bias = True, padding = 2)\n",
        "#         self.batch_norm4 = nn.BatchNorm1d(num_filters)\n",
        "#         self.relu4 = nn.ReLU()\n",
        "\n",
        "#         self.pool = nn.MaxPool1d(kernel_size = 2)\n",
        "\n",
        "#     def forward(self, x, print_sizes = False) -> torch.Tensor:\n",
        "#         \"\"\" Input x of size (batch size, embed_size, sent_len) and output of size [batchsize, embed_size] \"\"\"\n",
        "\n",
        "#         x_conv1 = self.conv1(x)\n",
        "#         x_relu1 = self.relu1(x_conv1)\n",
        "#         x_bn = self.batch_norm1(x_relu1)\n",
        "#         if print_sizes: print (x_bn.shape)\n",
        "\n",
        "#         x_conv2 = self.batch_norm2(self.relu2(self.conv2(x_bn)))\n",
        "#         if print_sizes: print (x_conv2.shape)\n",
        "\n",
        "#         x_conv3 = self.batch_norm3(self.relu3(self.conv3(x_conv2)))\n",
        "#         if print_sizes: print (x_conv3.shape)\n",
        "\n",
        "#         x_conv4 = self.batch_norm4(self.relu4(self.conv4(x_conv3)))\n",
        "#         if print_sizes: print (x_conv4.shape)\n",
        "\n",
        "#         x_pool = self.pool(x_conv4)\n",
        "#         # print (x_pool)\n",
        "#         if print_sizes: print(x_pool.shape)\n",
        "\n",
        "#         return x_pool\n",
        "\n",
        "# def test_all():\n",
        "#     batch_size = 3\n",
        "#     embed_size = 5\n",
        "#     sent_len = 6\n",
        "#     num_filters = 6\n",
        "\n",
        "#     fake_input = torch.tensor(np.zeros((batch_size, embed_size, sent_len)), dtype = torch.float32)\n",
        "#     block = ConvBlock(embed_size, num_filters)\n",
        "#     print (block.forward(fake_input, True))\n",
        "# #\n",
        "# #\n",
        "# if __name__ == '__main__':\n",
        "# #     #test_intermediate_sizes()\n",
        "# #     #test_output()\n",
        "#     test_all()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLWyw11qg_p0"
      },
      "outputs": [],
      "source": [
        "### deeperCNN ###\n",
        "# class DeepCNN(nn.Module):\n",
        "#     def __init__(self, embeddings, dropout=0.5):\n",
        "#         super().__init__()\n",
        "\n",
        "#         self.batch_size = embeddings.shape[1]\n",
        "\n",
        "#         # Freeze pretrained GloVe embeddings\n",
        "#         self.embedding = nn.Embedding(embeddings.shape[0], embeddings.shape[1])\n",
        "#         self.embedding.weight = nn.Parameter(torch.tensor(embeddings))\n",
        "#         self.embedding.weight.requires_grad = False\n",
        "\n",
        "#         self.conv = nn.Conv1d(in_channels=embeddings.shape[1], out_channels=128, kernel_size=5, padding = 2)\n",
        "#         #torch.nn.init.xavier_uniform_(self.conv.weight)\n",
        "#         self.block = ConvBlock(128, 256)\n",
        "#         self.block2 = ConvBlock(256, 256)\n",
        "\n",
        "#         self.dropout = nn.Dropout(dropout)\n",
        "#         self.fc = nn.Linear(5 * 256, 256)\n",
        "#         #self.relu = nn.ReLU()\n",
        "#         self.dropout2 = nn.Dropout(dropout)\n",
        "#         self.fc2 = nn.Linear(256, 1)\n",
        "#         #torch.nn.init.xavier_uniform_(self.fc.weight)\n",
        "\n",
        "#     def forward(self, x, print_sizes = False):\n",
        "#         # x.shape = (sent_len, batch_size)\n",
        "#         x = x.permute(1, 0)\n",
        "#         if print_sizes: print (\"x.shape: \" + str(x.shape))\n",
        "#         # x.shape = (batch_size, sent_len)\n",
        "\n",
        "#         x_emb = self.embedding(x).permute(0, 2, 1)\n",
        "#         if print_sizes: print (\"x_emb.shape: \" + str(x_emb.shape))\n",
        "#         # x_emb.shape = (batch_size, emb_size, sent_len)\n",
        "\n",
        "#         x_conv = self.conv(x_emb)\n",
        "#         # x_conv.shape = (batch_size, 128, sent_len)\n",
        "#         if print_sizes: print (\"x_conv.shape: \" + str(x_conv.shape))\n",
        "\n",
        "#         x_block = self.block.forward(x_conv)\n",
        "#         # x_block.shape = (batch_size, 128, sent_len / 2)\n",
        "#         if print_sizes: print (\"x_block.shape: \" + str(x_block.shape))\n",
        "\n",
        "#         x_block_2 = self.block2.forward(x_block)\n",
        "#         # x_block.shape = (batch_size, 256, sent_len / 4)\n",
        "#         if print_sizes: print (\"x_block_2.shape: \" + str(x_block_2.shape))\n",
        "\n",
        "#         x_cat = x_block_2.view(-1, x_block_2.shape[1] * x_block_2.shape[2])\n",
        "#         # x_cat.shape = (batch_size, 128 * sent_len / 2)\n",
        "#         if print_sizes: print (\"x_cat.shape: \" + str(x_cat.shape))\n",
        "\n",
        "#         x_fc = self.fc(self.dropout(x_cat))\n",
        "#         # x_fc.shape = (batch_size, 1)\n",
        "#         if print_sizes: print (\"x_fc.shape: \" + str(x_fc.shape))\n",
        "\n",
        "#         x_fc2 = self.fc2(self.dropout2(x_fc))\n",
        "\n",
        "#         return x_fc2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SI7TKVf9aRJJ"
      },
      "outputs": [],
      "source": [
        "# from DeepCNN import DeepCNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzhG_Qeha0OO"
      },
      "outputs": [],
      "source": [
        "embeddings_matrix = embeddings #renaming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6ohEkZ7DM_R"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "import sys\n",
        "from typing import List, Tuple, Dict, Set, Union\n",
        "\n",
        "\n",
        "import torch.nn.utils\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "import random\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import string\n",
        "\n",
        "#Ehsan 3 next lines\n",
        "# from TweetDataset import TweetDataset\n",
        "# from vocab import VocabEntry\n",
        "# from convblock import ConvBlock\n",
        "\n",
        "#from gensim.models import word2vec\n",
        "\n",
        "SEED = 1234"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCGzYuyPZZLH"
      },
      "outputs": [],
      "source": [
        "CNN_model = DeepCNN(embeddings_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eza8oVbatC96"
      },
      "source": [
        "# **#################################################**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTIKXuzYZZOv"
      },
      "outputs": [],
      "source": [
        "# device = torch.device('cpu') #('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "optimizer = optim.Adam(CNN_model.parameters())\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# CNN_model = CNN_model.to(device)\n",
        "\n",
        "# criterion = criterion.to(device)\n",
        "\n",
        "train_loader = DataLoader(train_dataset,\n",
        "                      batch_size=128,\n",
        "                      shuffle=True,\n",
        "                      num_workers=4\n",
        "                      # pin_memory=True # CUDA only\n",
        "                      )\n",
        "\n",
        "dev_loader = DataLoader(dev_dataset,\n",
        "                  batch_size=128,\n",
        "                  shuffle=False,\n",
        "                  num_workers=4\n",
        "                  # pin_memory=True # CUDA only\n",
        "                  )\n",
        "\n",
        "best_valid_acc = 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBeVUUovIRsd"
      },
      "outputs": [],
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division\n",
        "    acc = correct.sum()/len(correct)\n",
        "    return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmtGmY1cIZKy"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, dev_loader, criterion):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for batchnum, batch in enumerate(dev_loader):\n",
        "            dev_x = torch.stack(batch['content'])\n",
        "            #print (train_x)\n",
        "            dev_y = batch['label'].float()\n",
        "\n",
        "            predictions = model(dev_x).squeeze(1)\n",
        "            #print (torch.round(predictions))\n",
        "\n",
        "            loss = criterion(predictions, dev_y)\n",
        "\n",
        "            acc = binary_accuracy(predictions, dev_y)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(dev_loader), epoch_acc / len(dev_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJ_xlgfCIIsJ"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, optimizer, criterion):\n",
        "\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for batchnum, batch in enumerate(train_loader):\n",
        "        #print (\"Training on batch #\" + str(batchnum))\n",
        "        train_x = torch.stack(batch['content'])\n",
        "        #print (train_x.shape)\n",
        "        train_y = batch['label'].float()\n",
        "        #train_y = batch['label'].long()\n",
        "        if train_x.shape[1] == 1: continue\n",
        "        #print (train_y.view(-1).shape)\n",
        "\n",
        "        predictions = model.forward(train_x).squeeze(1)\n",
        "        #print (predictions.shape)\n",
        "        loss = criterion(predictions, train_y)\n",
        "        # print (loss)\n",
        "        loss.backward()\n",
        "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
        "        optimizer.step()\n",
        "        acc = binary_accuracy(predictions, train_y)\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(train_loader), epoch_acc / len(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8xR1VNEIyMe"
      },
      "outputs": [],
      "source": [
        "# MODEL_PATH = '/content/drive/MyDrive/models/cache'\n",
        "# MODEL_PATH = '/content/drive/MyDrive/models/model_cache/cache'\n",
        "MODEL_PATH = './cache'\n",
        "# MODEL_PATH = './model_cache/cache'\n",
        "N_EPOCHS = 70 # 20 #It was 4000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmhYqb7MAwwH"
      },
      "outputs": [],
      "source": [
        "best_valid_acc = 0\n",
        "\n",
        "train_loss_values = np.zeros(N_EPOCHS)\n",
        "train_acc_values = np.zeros(N_EPOCHS)\n",
        "\n",
        "valid_loss_values = np.zeros(N_EPOCHS)\n",
        "valid_acc_values = np.zeros(N_EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Xv1Fv8FZZSX",
        "outputId": "a20ba970-a686-4e5e-edae-06a82c9eb529"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Epoch: 01 | Train Loss: 0.668 | Train Acc: 65.52% |\n",
            "Begin validation\n",
            "| Val. Loss: 2.078 | Val. Acc: 66.39% |\n",
            "| Epoch: 02 | Train Loss: 0.597 | Train Acc: 70.99% |\n",
            "Begin validation\n",
            "| Val. Loss: 904.895 | Val. Acc: 74.34% |\n",
            "| Epoch: 03 | Train Loss: 0.573 | Train Acc: 72.62% |\n",
            "Begin validation\n",
            "| Val. Loss: 15.983 | Val. Acc: 67.20% |\n",
            "| Epoch: 04 | Train Loss: 0.563 | Train Acc: 73.47% |\n",
            "Begin validation\n",
            "| Val. Loss: 0.601 | Val. Acc: 76.25% |\n",
            "| Epoch: 05 | Train Loss: 0.552 | Train Acc: 74.15% |\n",
            "Begin validation\n",
            "| Val. Loss: 57216.306 | Val. Acc: 76.46% |\n",
            "| Epoch: 06 | Train Loss: 0.543 | Train Acc: 74.73% |\n",
            "Begin validation\n",
            "| Val. Loss: 14505.082 | Val. Acc: 74.17% |\n",
            "| Epoch: 07 | Train Loss: 0.537 | Train Acc: 75.10% |\n",
            "Begin validation\n",
            "| Val. Loss: 181.478 | Val. Acc: 77.20% |\n",
            "| Epoch: 08 | Train Loss: 0.530 | Train Acc: 75.62% |\n",
            "Begin validation\n",
            "| Val. Loss: 168.771 | Val. Acc: 78.43% |\n",
            "| Epoch: 09 | Train Loss: 0.523 | Train Acc: 75.99% |\n",
            "Begin validation\n",
            "| Val. Loss: 255.815 | Val. Acc: 79.62% |\n",
            "| Epoch: 10 | Train Loss: 0.519 | Train Acc: 76.27% |\n",
            "Begin validation\n",
            "| Val. Loss: 208.216 | Val. Acc: 75.26% |\n",
            "| Epoch: 11 | Train Loss: 0.512 | Train Acc: 76.54% |\n",
            "Begin validation\n",
            "| Val. Loss: 4.084 | Val. Acc: 79.72% |\n",
            "| Epoch: 12 | Train Loss: 0.508 | Train Acc: 76.98% |\n",
            "Begin validation\n",
            "| Val. Loss: 35.695 | Val. Acc: 73.55% |\n",
            "| Epoch: 13 | Train Loss: 0.502 | Train Acc: 77.23% |\n",
            "Begin validation\n",
            "| Val. Loss: 151.418 | Val. Acc: 79.73% |\n",
            "| Epoch: 14 | Train Loss: 0.495 | Train Acc: 77.69% |\n",
            "Begin validation\n",
            "| Val. Loss: 131.864 | Val. Acc: 71.06% |\n",
            "| Epoch: 15 | Train Loss: 0.489 | Train Acc: 77.99% |\n",
            "Begin validation\n",
            "| Val. Loss: 1.259 | Val. Acc: 79.38% |\n"
          ]
        }
      ],
      "source": [
        "# best_valid_acc = 0\n",
        "\n",
        "# train_loss_values = np.zeros(N_EPOCHS)\n",
        "# train_acc_values = np.zeros(N_EPOCHS)\n",
        "\n",
        "# valid_loss_values = np.zeros(N_EPOCHS)\n",
        "# valid_acc_values = np.zeros(N_EPOCHS)\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    train_loss, train_acc = train(CNN_model, train_loader, optimizer, criterion)\n",
        "\n",
        "    train_loss_values[N_EPOCHS - 1] = train_loss\n",
        "    train_acc_values[N_EPOCHS - 1] = train_acc\n",
        "\n",
        "    torch.save(CNN_model.state_dict(), MODEL_PATH)\n",
        "    torch.save(optimizer.state_dict(), MODEL_PATH + '.optim')\n",
        "    if True: # It was epoch % 2 == 0:\n",
        "        print (f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% |')\n",
        "        file = open(\"./losses.txt\", \"a\")\n",
        "        file.write(\"epoch: \" + str(epoch) + \" train_loss: \" + str(train_loss) + '\\n')\n",
        "\n",
        "    if True: # It was epoch % 5 == 0:\n",
        "        print (\"Begin validation\")\n",
        "        valid_loss, valid_acc = evaluate(CNN_model, dev_loader, criterion)\n",
        "\n",
        "        valid_loss_values[N_EPOCHS - 1] = valid_loss\n",
        "        valid_acc_values[N_EPOCHS - 1] = valid_acc\n",
        "\n",
        "        print (f'| Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}% |')\n",
        "\n",
        "        if valid_acc > best_valid_acc:\n",
        "            torch.save(CNN_model.state_dict(), MODEL_PATH)\n",
        "            torch.save(optimizer.state_dict(), MODEL_PATH + '.optim')\n",
        "            best_valid_acc = valid_acc\n",
        "\n",
        "        file = open(\"./losses.txt\", \"a\")\n",
        "        file.write(\"epoch: \" + str(epoch) + \" train_loss: \" + str(train_loss))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0gR0j3CfCXf"
      },
      "source": [
        "https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-a-general-checkpoint-for-inference-and-or-resuming-training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YvigTZe_RIM"
      },
      "outputs": [],
      "source": [
        "# ##Ehsan Added 14010624##\n",
        "# ## Begin\n",
        "# # CNN_model = TheModelClass(*args, **kwargs)\n",
        "# # optimizer = TheOptimizerClass(*args, **kwargs)\n",
        "\n",
        "# checkpoint = torch.load(MODEL_PATH)\n",
        "# CNN_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "# epoch = checkpoint['epoch']\n",
        "# loss = checkpoint['loss']\n",
        "\n",
        "# model.eval()\n",
        "# # - or -\n",
        "# # model.train()\n",
        "# ## End\n",
        "\n",
        "\n",
        "# # CNN_model.load_state_dict(torch.load(MODEL_PATH))\n",
        "# # CNN_model.load_state_dict(torch.load(MODEL_PATH + '.optim'))\n",
        "# # CNN_model.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqn0YLknUKVu"
      },
      "outputs": [],
      "source": [
        "################## Save to LOAD again ##################\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    train_loss, train_acc = train(CNN_model, train_loader, optimizer, criterion)\n",
        "\n",
        "    train_loss_values[epoch] = train_loss\n",
        "    train_acc_values[epoch] = train_acc\n",
        "\n",
        "#    torch.save(CNN_model.state_dict(), MODEL_PATH)\n",
        "#    torch.save(optimizer.state_dict(), MODEL_PATH + '.optim')\n",
        "\n",
        "\n",
        "    torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': CNN_model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': loss,\n",
        "                ...\n",
        "                }, MODEL_PATH)\n",
        "\n",
        "\n",
        "    if True: # It was epoch % 2 == 0:\n",
        "        print (f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% |')\n",
        "        file = open(\"./losses.txt\", \"a\")\n",
        "        file.write(\"epoch: \" + str(epoch) + \" train_loss: \" + str(train_loss) + '\\n')\n",
        "\n",
        "    if True: # It was epoch % 5 == 0:\n",
        "        # print (\"Begin validation\")\n",
        "        valid_loss, valid_acc = evaluate(CNN_model, dev_loader, criterion)\n",
        "\n",
        "        valid_loss_values[epoch] = valid_loss\n",
        "        valid_acc_values[epoch] = valid_acc\n",
        "\n",
        "        print (f'|          Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}% |')\n",
        "        print ('-----------------------------------------------------------------')\n",
        "\n",
        "        if valid_acc > best_valid_acc:\n",
        "            # torch.save(CNN_model.state_dict(), MODEL_PATH)\n",
        "            # torch.save(optimizer.state_dict(), MODEL_PATH + '.optim')\n",
        "\n",
        "            torch.save({\n",
        "                        'epoch': epoch,\n",
        "                        'model_state_dict': CNN_model.state_dict(),\n",
        "                        'optimizer_state_dict': optimizer.state_dict(),\n",
        "                        'loss': loss,\n",
        "                        ...\n",
        "                        }, MODEL_PATH)\n",
        "\n",
        "\n",
        "            best_valid_acc = valid_acc\n",
        "\n",
        "        file = open(\"./losses.txt\", \"a\")\n",
        "        file.write(\"epoch: \" + str(epoch) + \" train_loss: \" + str(train_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXXlZAEnHJTk"
      },
      "outputs": [],
      "source": [
        "# CNN_model = TheModelClass(*args, **kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyyuU606kVH2"
      },
      "source": [
        "| Epoch: 01 | Train Loss: 0.591 | Train Acc: 71.40% |\n",
        "|          Val. Loss: 9.735 | Val. Acc: 73.38% |\n",
        "-----------------------------------------------------------------\n",
        "| Epoch: 01 | Train Loss: 0.546 | Train Acc: 74.53% |\n",
        "|          Val. Loss: 609.560 | Val. Acc: 78.98% |\n",
        "-----------------------------------------------------------------\n",
        "| Epoch: 01 | Train Loss: 0.539 | Train Acc: 74.92% |\n",
        "|          Val. Loss: 496.271 | Val. Acc: 77.27% |\n",
        "-----------------------------------------------------------------\n",
        "| Epoch: 01 | Train Loss: 0.531 | Train Acc: 75.34% |\n",
        "|          Val. Loss: 35.134 | Val. Acc: 80.23% |\n",
        "-----------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlLIHpCBgeNq"
      },
      "outputs": [],
      "source": [
        "len(train_loss_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmJpbwGhOF3E"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0MHCBRE5q9W"
      },
      "outputs": [],
      "source": [
        "print('train_acc_values:',train_acc_values,'\\n')\n",
        "print('valid_acc_values:',valid_acc_values,'\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXEvUF2tiRE1"
      },
      "outputs": [],
      "source": [
        "x = range(0, (N_EPOCHS))\n",
        "\n",
        "# train_loss_values\n",
        "# train_acc_values\n",
        "# valid_loss_values\n",
        "# valid_acc_values\n",
        "# xpoints = np.array(train_loss_values, train_loss_values)\n",
        "\n",
        "plt.figure(figsize=(12,5), dpi=80)\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(x, train_acc_values, 'b', label='Traning acc')\n",
        "plt.plot(x, valid_acc_values, 'r', label='Validation acc')\n",
        "plt.title('Traning and Validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(x, train_loss_values, 'b', label='Traning loss')\n",
        "plt.plot(x, valid_loss_values, 'r', label='Validation loss')\n",
        "plt.title('Traning and Validation loss')\n",
        "plt.legend()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "noJQntjCWU7S"
      },
      "outputs": [],
      "source": [
        "\n",
        "plt.axis([0.7, 1, 0.6, 0.8])\n",
        "plt.xlabel('Training Accuracy')\n",
        "plt.ylabel('Validation Accuracy')\n",
        "plt.plot(train_acc_values, valid_acc_values)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_mc39os6UJE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygMxaNCn6UaL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}